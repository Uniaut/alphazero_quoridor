{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25.1\n",
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n",
    "\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quoridor game implementation\n",
    "import functools\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import heapq\n",
    "\n",
    "class QuoridorState:\n",
    "    '''\n",
    "    Quoridor state container class - generalized by size N\n",
    "    Attributes:\n",
    "        positions: 2x2 tuple representing the positions of the players\n",
    "        left_wall: 1x2 tuple representing the number of walls left for each player\n",
    "        walls: NxNx2 numpy array representing the walls\n",
    "    '''\n",
    "    def __init__(self, N: int = 9, n_walls: int = 10, copy: 'QuoridorState' = None):\n",
    "        self.N = N\n",
    "        if copy is not None:\n",
    "            self.N = copy.N\n",
    "            self.positions = copy.positions.copy()\n",
    "            self.left_wall = copy.left_wall.copy()\n",
    "            self.walls = copy.walls.copy()\n",
    "            self.board = copy.board.copy()\n",
    "        else:\n",
    "            self.positions = np.array([[0, self.N // 2], [self.N - 1, self.N // 2]])\n",
    "            self.left_wall = np.array([n_walls, n_walls])\n",
    "            self.walls = np.zeros((2, self.N - 1, self.N - 1), dtype=np.int8)\n",
    "            self.board = self.init_board()\n",
    "\n",
    "\n",
    "    def init_board(self):\n",
    "        '''\n",
    "        Returns a 2N-1x2N-1 numpy array representing the board\n",
    "        '''\n",
    "        board = np.zeros((self.N * 2 - 1, self.N * 2 - 1), dtype=np.int8)\n",
    "        board[1::2, 1::2] = 1\n",
    "        board[self.positions[0, 0] * 2, self.positions[0, 1] * 2] = 2\n",
    "        board[self.positions[1, 0] * 2, self.positions[1, 1] * 2] = 3\n",
    "        return board\n",
    "\n",
    "    def copy(self):\n",
    "        return QuoridorState(copy=self)\n",
    "    \n",
    "    def encode(self, player):\n",
    "        '''\n",
    "        Returns 4xNxN numpy array representing the state\n",
    "        channel 1: position of player 0\n",
    "        channel 2: position of player 1\n",
    "        channel 3: horizontal walls\n",
    "        channel 4: vertical walls\n",
    "        '''\n",
    "        encoded = np.zeros((4, self.N, self.N), dtype=np.float32)\n",
    "        encoded[player, self.positions[0, 0], self.positions[0, 1]] = 1\n",
    "        encoded[1 - player, self.positions[1, 0], self.positions[1, 1]] = 1\n",
    "        encoded[2, :, :] = np.pad(self.walls[0, :, :] == 1, ((0, 1), (0, 1)), 'constant', constant_values=0)\n",
    "        encoded[3, :, :] = np.pad(self.walls[1, :, :] == 1, ((0, 1), (0, 1)), 'constant', constant_values=0)\n",
    "        return encoded\n",
    "\n",
    "class Quoridor:\n",
    "    '''\n",
    "    Quoridor rule management class\n",
    "    '''\n",
    "    def __init__(self, N, n_walls):\n",
    "        self.N = N\n",
    "        self.n_walls = n_walls\n",
    "    \n",
    "    def get_initial_state(self):\n",
    "        '''\n",
    "        Returns the initial state of the game\n",
    "        '''\n",
    "        state = QuoridorState(self.N, self.n_walls)\n",
    "        return state\n",
    "    \n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def _search_on_board(self, state: QuoridorState, player):\n",
    "        '''\n",
    "        Returns the distance of shortest path to the goal of given player using a* algorithm.\n",
    "        1 is wall, 0 is path\n",
    "        if player 0: end at (2N - 2, *)\n",
    "        if player 1: end at (0, *)\n",
    "        heuristic: column-distance to the goal\n",
    "        '''\n",
    "        board = state.board\n",
    "        now_pos = state.positions[player] * 2\n",
    "        queue = []\n",
    "        heapq.heappush(queue, (2 * self.N - 2, 0, 0, now_pos))\n",
    "        \n",
    "        visited = np.zeros((2 * self.N - 1, 2 * self.N - 1), dtype=np.int8)\n",
    "        temp = 0\n",
    "        while queue:\n",
    "            _, _, g, pos = queue.pop()\n",
    "            if pos[0] < 0 or pos[0] > 2 * self.N - 2 or pos[1] < 0 or pos[1] > 2 * self.N - 2:\n",
    "                continue\n",
    "            if board[*pos] == 1 or visited[*pos] == 1:\n",
    "                continue\n",
    "            if pos[0] == (2 * self.N - 2) * (1 - player):\n",
    "                return g\n",
    "            \n",
    "            visited[*pos] = 1\n",
    "            for i in range(4):\n",
    "                e = np.array([[-1, 0], [1, 0], [0, -1], [0, 1]])[i]\n",
    "                new_pos = pos + e\n",
    "                h = (2 * self.N - 2 - new_pos[0]) * (1 - player) + (2 * new_pos[0]) * player\n",
    "                heapq.heappush(queue, (h + g + 1, temp := temp+1, g + 1, pos + e))\n",
    "        \n",
    "        return -1\n",
    "\n",
    "\n",
    "    def is_valid_wall(self, state: QuoridorState):\n",
    "        '''\n",
    "        Returns True if the state is valid, False otherwise\n",
    "        Conditions for a valid state:\n",
    "            - Walls are not blocking the path to the goal\n",
    "        '''\n",
    "        return self._search_on_board(state, 0) != -1 and self._search_on_board(state, 1) != -1\n",
    "    \n",
    "    def _search_valid_moves(self, state: QuoridorState, player):\n",
    "        '''\n",
    "        Returns a list of valid moves from the given position using dfs\n",
    "        1 is wall, 0 is path\n",
    "        2 is player 0, 3 is player 1\n",
    "        stack: [(pos, n_step)]\n",
    "        n_step stops at 2\n",
    "        reset step when board[pos] == 2 or 3\n",
    "        '''\n",
    "        board = state.board\n",
    "        now_pos = state.positions[player] * 2\n",
    "        movable = []\n",
    "        stack = []\n",
    "        stack.append((now_pos, 0))\n",
    "        visited = np.zeros((2 * self.N - 1, 2 * self.N - 1), dtype=np.int8)\n",
    "        while len(stack) > 0:\n",
    "            pos, step = stack.pop()\n",
    "            if pos[0] < 0 or pos[0] > 2 * self.N - 2 or pos[1] < 0 or pos[1] > 2 * self.N - 2:\n",
    "                continue\n",
    "            if board[*pos] == 1 or visited[*pos] == 1:\n",
    "                continue\n",
    "            if board[*pos] == 2 or board[*pos] == 3:\n",
    "                step = 0\n",
    "            visited[*pos] = 1\n",
    "            if step == 2:\n",
    "                movable.append(pos // 2)\n",
    "                continue\n",
    "            for e in np.array([[-1, 0], [1, 0], [0, -1], [0, 1]]):\n",
    "                stack.append((pos + e, step + 1))\n",
    "\n",
    "        return movable\n",
    "\n",
    "\n",
    "    def is_valid_move(self, state: QuoridorState, next_pos, player):\n",
    "        '''\n",
    "        Returns True if the next state is a valid move, False otherwise\n",
    "        Conditions for a valid move:\n",
    "            - The player is moving to a valid position\n",
    "        '''\n",
    "        cvt_pos = np.array(next_pos)\n",
    "        if any([np.array_equal(cvt_pos, val_mov) for val_mov in self._search_valid_moves(state, player)]):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def get_next_state(self, state: QuoridorState, action: tuple, player: int):\n",
    "        '''\n",
    "        Returns the next state of the game given the current state and action\n",
    "        '''\n",
    "        action_type, action_value = action\n",
    "        next_state = QuoridorState(copy=state)\n",
    "        if action_type == 0:\n",
    "            if self.is_valid_move(next_state, action_value, player):\n",
    "                next_state.board[*next_state.positions[player] * 2] = 0\n",
    "                next_state.board[*np.array(action_value) * 2] = player + 2\n",
    "                next_state.positions[player] = action_value\n",
    "                return next_state\n",
    "            else:\n",
    "                # print('Invalid move')\n",
    "                return None\n",
    "        else:\n",
    "            if next_state.left_wall[player] == 0:\n",
    "                # print('No wall left')\n",
    "                return None\n",
    "            \n",
    "            hv = action_type - 1\n",
    "            row, col = action_value\n",
    "            if next_state.walls[hv, row, col] != 0:\n",
    "                # print('Invalid wall')\n",
    "                return None\n",
    "            \n",
    "            next_state.walls[hv, row, col] = 1\n",
    "            next_state.walls[1 - hv, row, col] = -1\n",
    "            if hv == 0 and col > 0:\n",
    "                next_state.walls[0, row, col - 1] = -1\n",
    "            if hv == 1 and row > 0:\n",
    "                next_state.walls[1, row - 1, col] = -1\n",
    "            if hv == 0 and col < self.N - 2:\n",
    "                next_state.walls[0, row, col + 1] = -1\n",
    "            if hv == 1 and row < self.N - 2:\n",
    "                next_state.walls[1, row + 1, col] = -1\n",
    "            next_state.board[\n",
    "                row * 2 - hv + 1 : row * 2 + hv + 2,\n",
    "                col * 2 - (1 - hv) + 1 : col * 2 + (1 - hv) + 2\n",
    "            ] = 1\n",
    "            next_state.left_wall[player] -= 1\n",
    "            if not self.is_valid_wall(next_state):\n",
    "                # print('Invalid wall')\n",
    "                return None\n",
    "\n",
    "            return next_state\n",
    "\n",
    "    def get_valid_actions(self, state: QuoridorState, player: int):\n",
    "        moves = self._search_valid_moves(state, player)\n",
    "        walls = [\n",
    "            (hv, (r, c))\n",
    "            for hv in range(2) for r in range(self.N - 1) for c in range(self.N - 1) \n",
    "            if self.get_next_state(state, (hv + 1, (r, c)), player) is not None\n",
    "        ]\n",
    "        actions = np.zeros((3, self.N, self.N))\n",
    "        for move in moves:\n",
    "            actions[0, *move] = 1\n",
    "        for hv, p in walls:\n",
    "            actions[1 + hv, *p] = 1\n",
    "        return actions\n",
    "\n",
    "    def check_win(self, state: QuoridorState, player):\n",
    "        '''\n",
    "        Returns True if the player wins, False otherwise\n",
    "        '''\n",
    "        if state.positions[player][0] == (self.N - 1) * (1 - player):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def get_draw_value(self, state: QuoridorState, player: int):\n",
    "        '''\n",
    "        Returns the reward of the given state. Possibly value can be heuristic, not only win-lose.\n",
    "        '''\n",
    "        p_value = self._search_on_board(state, player)\n",
    "        o_value = self._search_on_board(state, 1 - player)\n",
    "        return p_value / (p_value + o_value)\n",
    "        \n",
    "    def get_value_and_terminated(self, state: QuoridorState, player: int, turn_count: int):\n",
    "        '''\n",
    "        Returns whether the game is terminated and the reward of the given state.\n",
    "        If the game progresses more than 50 turns, the game is forced to terminate.\n",
    "        '''\n",
    "        if turn_count > 50:\n",
    "            return True, True, self.get_draw_value(state, player)\n",
    "        if self.check_win(state, player):\n",
    "            return True, False, 1\n",
    "        else:\n",
    "            return False, False, 0\n",
    "        \n",
    "\n",
    "def parse_cmd(cmd: str) -> tuple:\n",
    "    s = cmd.split(' ')\n",
    "    if s[0] == 'move':\n",
    "        return 0, (int(s[1]), int(s[2]))\n",
    "    elif s[0] == 'wall':\n",
    "        return 1 + s[1], (int(s[2]), int(s[3]))\n",
    "    else:\n",
    "        raise ValueError('Invalid action type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model implementation for AlphaZero\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(n_channels, n_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels)\n",
    "        self.conv2 = nn.Conv2d(n_channels, n_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(n_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "class QuoridorNet(nn.Module):\n",
    "    def __init__(self, game: Quoridor, num_resBlocks, n_channels):\n",
    "        super().__init__()\n",
    "        self.start_block = nn.Sequential(\n",
    "            nn.Conv2d(4, n_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(n_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.backbone = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [('backbone_resblock_{}'.format(i), ResBlock(n_channels)) for i in range(num_resBlocks)]\n",
    "            \n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, n_channels, 1, padding=0),\n",
    "            nn.BatchNorm2d(n_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_channels, 3, 1, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, 3, 1, padding=0),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * game.N * game.N, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.start_block(x)\n",
    "        x = self.backbone(x)\n",
    "        p = self.policy_head(x)\n",
    "        v = self.value_head(x)\n",
    "        return p, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import product, chain\n",
    "\n",
    "import tqdm\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(\n",
    "            self,\n",
    "            game: Quoridor,\n",
    "            args,\n",
    "            state: QuoridorState,\n",
    "            player,\n",
    "            turn_count: int,\n",
    "            parent: 'Node' = None,\n",
    "            action_taken = None):\n",
    "        \n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.state = state\n",
    "        self.player = player\n",
    "        self.turn_count = turn_count\n",
    "        self.parent = parent\n",
    "        self.action_taken = action_taken\n",
    "\n",
    "        self.children: list['Node'] = []\n",
    "        self.expandable_actions = self.game.get_valid_actions(self.state, self.player)\n",
    "\n",
    "        self.visit_count = 0\n",
    "        self.total_value = 0\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "    \n",
    "    def select(self) -> 'Node':\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf\n",
    "\n",
    "        for child in self.children:\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_ucb = ucb\n",
    "                best_child = child\n",
    "\n",
    "        return best_child\n",
    "\n",
    "    def get_ucb(self, child: 'Node'):\n",
    "        q_value = child.total_value / (child.visit_count + 1e-8)\n",
    "        return q_value + self.args['C'] * math.sqrt(math.log(self.visit_count) / (child.visit_count + 1e-8))\n",
    "    \n",
    "\n",
    "    def expand(self, actions, policy):\n",
    "        for action in zip(*np.where(actions == 1.0)):\n",
    "            if policy[*action] > 0.0:\n",
    "                child_state = self.state.copy()\n",
    "                a_t, r, c = action\n",
    "                child_state = self.game.get_next_state(child_state, (a_t, (r, c)), 1 - self.player)\n",
    "\n",
    "                child = Node(self.game, self.args, child_state, 1 - self.player, self.turn_count + 1, self, action)\n",
    "                self.children.append(child)\n",
    "\n",
    "    def backpropagate(self, value, is_draw):\n",
    "        self.visit_count += 1\n",
    "        if is_draw:\n",
    "            self.total_value += value * self.args['draw_discount']\n",
    "        else:\n",
    "            self.total_value += value\n",
    "\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value, is_draw)\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game: Quoridor, args, model) -> None:\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "\n",
    "    def search(self, state, player):\n",
    "        root = Node(self.game, self.args, state, 1 - player, 0)\n",
    "\n",
    "        for search in tqdm.trange(self.args['n_searches']):\n",
    "            # print(search)\n",
    "            node = root\n",
    "\n",
    "            while node.is_fully_expanded():\n",
    "                # print(node.expandable_actions, node.children)\n",
    "                node = node.select()\n",
    "\n",
    "            is_terminal, is_draw, value = self.game.get_value_and_terminated(node.state, 1 - node.player, node.turn_count)\n",
    "\n",
    "            if not is_terminal:\n",
    "                policy, value = self.model(\n",
    "                    torch.tensor(node.state.encode(1 - node.player)).unsqueeze(0)\n",
    "                )\n",
    "                policy = torch.flatten(policy, start_dim=1, end_dim=3)\n",
    "                policy = torch.softmax(policy, axis=1).squeeze(0).detach()\n",
    "                policy = torch.reshape(policy, (3, self.game.N, self.game.N)).numpy()\n",
    "                \n",
    "                valid_moves = self.game.get_valid_actions(node.state, 1 - node.player)\n",
    "                policy *= valid_moves\n",
    "                policy /= np.sum(policy)\n",
    "\n",
    "                value = value.unsqueeze(0).item()\n",
    "\n",
    "                node.expand(valid_moves, policy)\n",
    "                \n",
    "            node.backpropagate(value, is_draw)\n",
    "        \n",
    "        action_probs = np.zeros((3, self.game.N, self.game.N), dtype=np.float32)\n",
    "        for idx, child in enumerate(root.children):\n",
    "            action_probs[*child.action_taken] = child.total_value / (child.visit_count + 1e-8)\n",
    "        action_probs /= np.sum(action_probs, axis=(0, 1, 2))\n",
    "        return action_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_policy(policy, state: QuoridorState, player):\n",
    "    if policy is None:\n",
    "        policy = np.zeros((3, state.N, state.N))\n",
    "    plt.figure(num=0)\n",
    "    plt.axis()\n",
    "    rect = plt.Rectangle((-0.5, -0.5), state.N, state.N, fc='w', ec='k')\n",
    "    plt.gca().add_patch(rect)\n",
    "    \n",
    "    for i in range(state.N):\n",
    "        for j in range(state.N):\n",
    "            rate = float(policy[0, i, j])\n",
    "            color = np.array([1-rate, 0, rate, 1]) if policy[0, i, j] > 0.0 else 'w'\n",
    "            rect = plt.Rectangle((i-0.3, j-0.3), 0.6, 0.6, fc=color, ec='k')\n",
    "            plt.gca().add_patch(rect)\n",
    "\n",
    "    for i in range(state.N - 1):\n",
    "        for j in range(state.N - 1):\n",
    "            rate = float(policy[0, i, j])\n",
    "            color = np.array([1-rate, 0, rate, 1]) if state.walls[0, i, j] != 1 else 'k'\n",
    "            rect = plt.Rectangle((i+0.5-0.1, j+0.5-0.5), 0.2, 1, fc=color, ec='k')\n",
    "            plt.gca().add_patch(rect)\n",
    "            \n",
    "            rate = float(policy[0, i, j])\n",
    "            color = np.array([1-rate, 0, rate, 1]) if state.walls[1, i, j] != 1 else 'k'\n",
    "            rect = plt.Rectangle((i+0.5-0.5, j+0.5-0.1), 1, 0.2, fc=color, ec='k')\n",
    "            plt.gca().add_patch(rect)\n",
    "\n",
    "            rect = plt.Rectangle((i+0.5-0.1, j+0.5-0.1), 0.2, 0.2, fc='k', ec='k')\n",
    "            plt.gca().add_patch(rect)\n",
    "\n",
    "\n",
    "\n",
    "    circle = plt.Circle((state.positions[0, 0], state.positions[0, 1]), 0.1, fc='g' if player == 0 else 'w', ec='k')\n",
    "    plt.gca().add_patch(circle)\n",
    "    circle = plt.Circle((state.positions[1, 0], state.positions[1, 1]), 0.1, fc='g' if player == 1 else 'k', ec='k')\n",
    "    plt.gca().add_patch(circle)\n",
    "\n",
    "    plt.axis('scaled')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:06<00:01,  1.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m plot_policy(\u001b[39mNone\u001b[39;00m, state, player)\n\u001b[1;32m     18\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     mcts_probs \u001b[39m=\u001b[39m mcts\u001b[39m.\u001b[39;49msearch(state, player)\n\u001b[1;32m     20\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munravel_index(np\u001b[39m.\u001b[39margmax(mcts_probs), mcts_probs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     22\u001b[0m     a_t, r, c \u001b[39m=\u001b[39m action\n",
      "Cell \u001b[0;32mIn[5], line 106\u001b[0m, in \u001b[0;36mMCTS.search\u001b[0;34m(self, state, player)\u001b[0m\n\u001b[1;32m    102\u001b[0m         policy \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(policy)\n\u001b[1;32m    104\u001b[0m         value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m--> 106\u001b[0m         node\u001b[39m.\u001b[39;49mexpand(valid_moves, policy)\n\u001b[1;32m    108\u001b[0m     node\u001b[39m.\u001b[39mbackpropagate(value, is_draw)\n\u001b[1;32m    110\u001b[0m action_probs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m3\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame\u001b[39m.\u001b[39mN, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame\u001b[39m.\u001b[39mN), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "Cell \u001b[0;32mIn[5], line 59\u001b[0m, in \u001b[0;36mNode.expand\u001b[0;34m(self, actions, policy)\u001b[0m\n\u001b[1;32m     56\u001b[0m a_t, r, c \u001b[39m=\u001b[39m action\n\u001b[1;32m     57\u001b[0m child_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame\u001b[39m.\u001b[39mget_next_state(child_state, (a_t, (r, c)), \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplayer)\n\u001b[0;32m---> 59\u001b[0m child \u001b[39m=\u001b[39m Node(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgame, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, child_state, \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplayer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mturn_count \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m, action)\n\u001b[1;32m     60\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren\u001b[39m.\u001b[39mappend(child)\n",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m, in \u001b[0;36mNode.__init__\u001b[0;34m(self, game, args, state, player, turn_count, parent, action_taken)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_taken \u001b[39m=\u001b[39m action_taken\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren: \u001b[39mlist\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mNode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpandable_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgame\u001b[39m.\u001b[39;49mget_valid_actions(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplayer)\n\u001b[1;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_value \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 212\u001b[0m, in \u001b[0;36mQuoridor.get_valid_actions\u001b[0;34m(self, state, player)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_valid_actions\u001b[39m(\u001b[39mself\u001b[39m, state: QuoridorState, player: \u001b[39mint\u001b[39m):\n\u001b[1;32m    211\u001b[0m     moves \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_search_valid_moves(state, player)\n\u001b[0;32m--> 212\u001b[0m     walls \u001b[39m=\u001b[39m [\n\u001b[1;32m    213\u001b[0m         (hv, (r, c))\n\u001b[1;32m    214\u001b[0m         \u001b[39mfor\u001b[39;49;00m hv \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m2\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m r \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mN \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mN \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m) \n\u001b[1;32m    215\u001b[0m         \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_next_state(state, (hv \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, (r, c)), player) \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    216\u001b[0m     ]\n\u001b[1;32m    217\u001b[0m     actions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m3\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN))\n\u001b[1;32m    218\u001b[0m     \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m moves:\n",
      "Cell \u001b[0;32mIn[3], line 215\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_valid_actions\u001b[39m(\u001b[39mself\u001b[39m, state: QuoridorState, player: \u001b[39mint\u001b[39m):\n\u001b[1;32m    211\u001b[0m     moves \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_search_valid_moves(state, player)\n\u001b[1;32m    212\u001b[0m     walls \u001b[39m=\u001b[39m [\n\u001b[1;32m    213\u001b[0m         (hv, (r, c))\n\u001b[1;32m    214\u001b[0m         \u001b[39mfor\u001b[39;00m hv \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \n\u001b[0;32m--> 215\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_next_state(state, (hv \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, (r, c)), player) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     ]\n\u001b[1;32m    217\u001b[0m     actions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m3\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN))\n\u001b[1;32m    218\u001b[0m     \u001b[39mfor\u001b[39;00m move \u001b[39min\u001b[39;00m moves:\n",
      "Cell \u001b[0;32mIn[3], line 204\u001b[0m, in \u001b[0;36mQuoridor.get_next_state\u001b[0;34m(self, state, action, player)\u001b[0m\n\u001b[1;32m    199\u001b[0m next_state\u001b[39m.\u001b[39mboard[\n\u001b[1;32m    200\u001b[0m     row \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m-\u001b[39m hv \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m : row \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m hv \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[1;32m    201\u001b[0m     col \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m-\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m hv) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m : col \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m hv) \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    202\u001b[0m ] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    203\u001b[0m next_state\u001b[39m.\u001b[39mleft_wall[player] \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mis_valid_wall(next_state):\n\u001b[1;32m    205\u001b[0m     \u001b[39m# print('Invalid wall')\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39mreturn\u001b[39;00m next_state\n",
      "Cell \u001b[0;32mIn[3], line 115\u001b[0m, in \u001b[0;36mQuoridor.is_valid_wall\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_valid_wall\u001b[39m(\u001b[39mself\u001b[39m, state: QuoridorState):\n\u001b[1;32m    110\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m    Returns True if the state is valid, False otherwise\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m    Conditions for a valid state:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m        - Walls are not blocking the path to the goal\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_search_on_board(state, \u001b[39m0\u001b[39;49m) \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_search_on_board(state, \u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 104\u001b[0m, in \u001b[0;36mQuoridor._search_on_board\u001b[0;34m(self, state, player)\u001b[0m\n\u001b[1;32m    102\u001b[0m         new_pos \u001b[39m=\u001b[39m pos \u001b[39m+\u001b[39m e\n\u001b[1;32m    103\u001b[0m         h \u001b[39m=\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m \u001b[39m-\u001b[39m new_pos[\u001b[39m0\u001b[39m]) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m player) \u001b[39m+\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m new_pos[\u001b[39m0\u001b[39m]) \u001b[39m*\u001b[39m player\n\u001b[0;32m--> 104\u001b[0m         heapq\u001b[39m.\u001b[39mheappush(queue, (h \u001b[39m+\u001b[39m g \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, temp \u001b[39m:=\u001b[39m temp\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, g \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, pos \u001b[39m+\u001b[39m e))\n\u001b[1;32m    106\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "quoridor = Quoridor(5, 6)\n",
    "\n",
    "args = {\n",
    "    'C': 1.4,\n",
    "    'n_searches': 10,\n",
    "    'draw_discount': 0.2,\n",
    "}\n",
    "\n",
    "model = QuoridorNet(quoridor, 1, 5)\n",
    "model.eval()\n",
    "\n",
    "mcts = MCTS(quoridor, args, model)\n",
    "\n",
    "state = quoridor.get_initial_state()\n",
    "\n",
    "player = 0\n",
    "plot_policy(None, state, player)\n",
    "while True:\n",
    "    mcts_probs = mcts.search(state, player)\n",
    "    action = np.unravel_index(np.argmax(mcts_probs), mcts_probs.shape)\n",
    "\n",
    "    a_t, r, c = action\n",
    "    new_state = quoridor.get_next_state(state, (a_t, (r, c)), player)\n",
    "\n",
    "    if new_state is None:\n",
    "        print(action)\n",
    "        print(quoridor.get_valid_actions(new_state, player))\n",
    "\n",
    "    plot_policy(mcts_probs, new_state, player)\n",
    "\n",
    "    state = new_state\n",
    "\n",
    "    is_terminal = quoridor.check_win(state, player)\n",
    "\n",
    "    if is_terminal:\n",
    "        print('Player {} wins'.format(player))\n",
    "        break\n",
    "\n",
    "\n",
    "    player = 1 - player\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZero:\n",
    "    def __init__(self, model: nn.Module, optimizer, game: Quoridor, args):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.mcts = MCTS(game, args, model)\n",
    "\n",
    "    def selfplay(self):\n",
    "        memory = []\n",
    "        player = 1\n",
    "        state = self.game.get_initial_state()\n",
    "\n",
    "        while True:\n",
    "            mcts_probs = self.mcts.search(state, player)\n",
    "            memory.append((state, mcts_probs, player))\n",
    "\n",
    "            best_action = np.unravel_index(np.argmax(mcts_probs), mcts_probs.shape)\n",
    "            a_t, r, c = best_action\n",
    "            state = quoridor.get_next_state(state, (a_t, (r, c)), player)\n",
    "\n",
    "            is_terminal, _, value = self.game.get_value_and_terminated(state, player, 0)\n",
    "\n",
    "            if is_terminal:\n",
    "                return_memory = []\n",
    "                for hist_state, hist_mcts_prob, hist_player in memory:\n",
    "                    hist_value = value if hist_player == player else 1 - value\n",
    "                    return_memory.append((hist_state.encode(hist_player), hist_mcts_prob, hist_value))\n",
    "                return return_memory\n",
    "\n",
    "            player = 1 - player\n",
    "\n",
    "    def train(self, memory):\n",
    "        pass\n",
    "\n",
    "    def learn(self):\n",
    "        for i in range(self.args['n_iterations']):\n",
    "            memory = []\n",
    "            self.model.eval()\n",
    "            \n",
    "            for selfplay_i in range(self.args['n_selfplay_iterations']):\n",
    "                memory.extend(self.selfplay())\n",
    "            \n",
    "            self.model.train()\n",
    "            for epoch in range(self.args['n_epochs']):\n",
    "                self.train(memory)\n",
    "            \n",
    "            torch.save(self.model.state_dict(), f'./model_{i}.pt')\n",
    "            torch.save(self.optimizer.state_dict(), f'./optimizer_{i}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 66.42it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 215.59it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 261.75it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 283.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 318.57it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 675.37it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 699.25it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1483.03it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1700.37it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1448.86it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.19it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 216.71it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 276.36it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 316.15it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 327.19it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 682.50it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 750.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1583.53it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1622.05it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1585.57it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 81.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 215.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 276.89it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 306.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 334.43it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 675.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 354.85it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 951.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1725.70it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1479.11it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 78.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 214.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 279.69it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 309.87it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 323.84it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 668.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 749.00it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1557.37it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1685.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1714.06it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 81.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 177.36it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 280.61it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 314.58it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 321.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 606.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 719.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1491.84it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1658.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1759.06it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 81.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 216.36it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 256.00it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 309.15it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 324.70it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 303.90it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 657.68it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1421.89it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1752.81it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1616.80it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 74.61it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 204.49it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 67.84it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 279.06it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 314.46it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 595.13it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 734.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1471.63it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1722.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1571.37it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 79.29it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 209.77it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 271.51it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 300.63it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 319.44it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 649.69it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 757.16it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1544.81it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1752.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1710.84it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 69.65it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 183.51it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 265.64it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 302.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 306.86it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 674.90it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 757.05it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 697.89it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 828.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1388.70it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.46it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 213.70it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 278.21it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 302.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 308.34it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 621.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 676.17it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1457.72it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1372.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1668.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 78.94it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 218.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 273.06it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 277.00it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 219.98it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 640.95it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 695.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1483.66it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1551.84it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1631.64it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.77it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 207.63it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 261.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 311.92it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 326.46it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 677.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 743.59it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1534.46it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1819.50it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1832.85it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 78.57it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 211.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 270.75it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 307.13it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 323.77it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 682.46it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 682.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1497.91it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 408.58it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 931.72it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 81.57it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 217.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 271.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 309.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 328.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 695.02it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 777.56it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1380.84it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1679.80it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1674.51it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 81.90it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 212.57it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 274.86it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 310.43it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 335.65it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 676.33it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 746.66it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1320.50it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1768.03it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1609.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 69.42it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 194.32it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 279.67it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 313.99it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 332.62it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 708.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 759.37it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1467.16it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1497.86it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1691.46it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 78.65it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 169.46it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 248.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 289.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 311.73it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 649.40it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 730.46it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1497.91it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1855.97it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1669.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.10it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 151.33it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 274.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 318.29it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 328.34it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 679.61it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 740.68it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1499.52it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1610.10it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1519.29it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 79.59it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 212.34it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 280.69it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 295.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 320.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 683.43it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 689.38it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1551.43it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1661.44it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1751.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.60it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 214.72it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 176.29it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 284.13it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 319.06it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 697.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 732.27it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1535.59it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1732.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1741.53it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.95it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 218.85it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 277.55it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 321.25it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 241.00it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 629.06it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 741.24it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1521.60it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1738.50it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1726.83it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.87it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 216.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 273.87it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 315.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 197.70it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 673.96it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 750.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1568.61it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1697.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1708.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.67it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 217.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 275.92it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 315.77it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 325.80it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 727.91it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 753.92it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1546.12it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1807.27it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1795.97it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 81.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 217.36it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 276.04it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 310.81it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 190.53it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 672.14it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 768.05it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1533.73it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1812.89it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1570.37it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 81.12it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 180.35it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 274.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 311.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 324.82it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 682.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 740.52it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1603.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1726.26it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1697.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.77it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 217.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 274.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 307.52it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 328.45it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 697.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 233.61it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1361.43it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1558.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1698.10it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 81.61it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 220.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 276.24it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 311.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 326.14it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 672.41it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 752.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1490.99it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1698.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1847.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.79it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 217.97it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 210.35it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 307.87it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 329.62it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 697.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 771.38it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1540.83it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1779.74it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 365.72it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 212.82it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 280.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 312.89it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 323.91it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 645.69it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 700.04it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1581.98it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1695.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1724.49it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 80.09it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 208.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 259.67it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 299.37it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 325.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 649.44it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 721.14it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1277.78it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1526.03it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1569.90it/s]\n"
     ]
    }
   ],
   "source": [
    "quoridor = Quoridor(3, 6)\n",
    "\n",
    "model = QuoridorNet(quoridor, 3, 3)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'n_searches': 10,\n",
    "    'n_iterations': 3,\n",
    "    'n_selfplay_iterations': 10,\n",
    "    'n_epochs': 4,\n",
    "}\n",
    "\n",
    "alphazero = AlphaZero(model, optimizer, quoridor, args)\n",
    "alphazero.learn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
